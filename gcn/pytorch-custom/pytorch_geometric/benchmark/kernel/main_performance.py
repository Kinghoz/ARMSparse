import argparse
from itertools import product

import torch
from datasets import get_dataset
from gcn import GCN
from gin import GIN
from graph_sage import GraphSAGE
from train_eval import eval_acc, train

from torch_geometric import seed_everything
from torch_geometric.loader import DataLoader
from torch_geometric.profile import get_stats_summary, profileit, timeit

seed_everything(0)

parser = argparse.ArgumentParser()
parser.add_argument('--epochs', type=int, default=100)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--lr', type=float, default=0.01)
parser.add_argument('--warmup_profile', type=int, default=1,
                    help='Skip the first few runs')
parser.add_argument('--goal_accuracy', type=int, default=1,
                    help='The goal test accuracy')
args = parser.parse_args()

layers = [1, 2, 3]
hiddens = [16, 32]

datasets = ['MUTAG', 'PROTEINS', 'IMDB-BINARY', 'REDDIT-BINARY']

nets = [
    GCN,
    GraphSAGE,
    GIN,
]

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Decorate train and eval functions:
train = profileit(print_layer_stats=False)(train)
eval_acc = timeit()(eval_acc)

for dataset_name, Net in product(datasets, nets):
    dataset = get_dataset(dataset_name, sparse=True)
    num_train = int(len(dataset) * 0.8)
    num_val = int(len(dataset) * 0.1)

    train_dataset = dataset[:num_train]
    val_dataset = dataset[num_train:num_train + num_val]
    test_dataset = dataset[num_train + num_val:]

    train_loader = DataLoader(train_dataset, batch_size=args.batch_size,
                              shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size,
                            shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size,
                             shuffle=False)

    for num_layers, hidden in product(layers, hiddens):
        print(f'--\n{dataset_name} - {Net.__name__} - {num_layers} - {hidden}')

        model = Net(dataset, num_layers, hidden).to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

        stats_list = []
        for epoch in range(1, args.epochs + 1):
            loss, stats = train(model, optimizer, train_loader)
            val_acc, val_time = eval_acc(model, val_loader)
            test_acc, test_time = eval_acc(model, test_loader)

            if epoch >= args.warmup_profile:
                stats_list.append(stats)

        stats_summary = get_stats_summary(stats_list)
        print(stats_summary)
